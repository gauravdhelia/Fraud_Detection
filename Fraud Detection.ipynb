{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries, visualization tools, machine learning models and metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acquire and describe the data\n",
    "dataframe = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Time' 'V1' 'V2' 'V3' 'V4' 'V5' 'V6' 'V7' 'V8' 'V9' 'V10' 'V11' 'V12'\n",
      " 'V13' 'V14' 'V15' 'V16' 'V17' 'V18' 'V19' 'V20' 'V21' 'V22' 'V23' 'V24'\n",
      " 'V25' 'V26' 'V27' 'V28' 'Amount' 'Class']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataframe.columns.values)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "           ...                 V21           V22           V23           V24  \\\n",
       "count      ...        2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...        1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std        ...        7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min        ...       -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%        ...       -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%        ...       -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%        ...        1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max        ...        2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0\n",
      "Time    0\n",
      "V1      0\n",
      "V2      0\n",
      "V3      0\n",
      "V4      0\n",
      "V5      0\n",
      "V6      0\n",
      "V7      0\n",
      "V8      0\n",
      "V9      0\n",
      "V10     0\n",
      "V11     0\n",
      "V12     0\n",
      "V13     0\n",
      "V14     0\n",
      "V15     0\n",
      "V16     0\n",
      "V17     0\n",
      "V18     0\n",
      "V19     0\n",
      "V20     0\n",
      "V21     0\n",
      "V22     0\n",
      "V23     0\n",
      "V24     0\n",
      "V25     0\n",
      "V26     0\n",
      "V27     0\n",
      "V28     0\n",
      "Amount  0\n",
      "Class   0\n"
     ]
    }
   ],
   "source": [
    "#Checking for columns with null entries\n",
    "df=pd.DataFrame(len(dataframe)-dataframe.count())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "0    284315\n",
      "1       492\n",
      "Name: V1, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAE9VJREFUeJzt3X+s3fV93/Hna3ahWdMEEwxjmNak9bY60eoQi1jJtCWhAkOkmWigGa3FzTy5yWBqtP4Rp5lERIpGOrVMaCkTCR4m6yCMNsJTnFHXMEVVAuHSEn6EEt8AC6497GCHUkUlhbz3x/nc5vhyfO/H917fY4fnQ/rqfM/7+/l+v+/zzUle/v44N6kqJEnq8XfG3YAk6eRhaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6rZ03A0stDPOOKNWrlw57jYk6aTy8MMPf7eqls827scuNFauXMnExMS425Ckk0qS/9szzstTkqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG4/dr8In4+VW7807hZ0gnr2hg+MuwXphOCZhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkbrOGRpJzk9yf5MkkTyT59Vb/ZJK/SPJImy4dWufjSSaTPJXk4qH6+labTLJ1qH5ekgeT7EnyhSSntPqp7f1kW75yIT+8JOnY9JxpvAL8RlX9ArAOuDrJ6rbsxqpa06adAG3ZRuBtwHrg95IsSbIE+AxwCbAauHJoO59u21oFHAY2t/pm4HBV/TxwYxsnSRqTWUOjqvZX1Z+2+ZeAJ4FzZlhlA3BnVb1cVc8Ak8AFbZqsqqer6gfAncCGJAHeD9zd1t8OXDa0re1t/m7gwjZekjQGx3RPo10eegfwYCtdk+TRJNuSLGu1c4Dnhlbb22pHq78F+F5VvTKtfsS22vIX23hJ0hh0h0aSNwJ/AHy0qv4SuBn4OWANsB/4namhI1avOdRn2tb03rYkmUgycfDgwRk/hyRp7rpCI8lPMAiM36+qPwSoquer6tWq+iHwWQaXn2BwpnDu0OorgH0z1L8LnJZk6bT6Edtqy98MHJreX1XdUlVrq2rt8uXLez6SJGkOep6eCnAr8GRV/e5Q/eyhYR8EHm/zO4CN7cmn84BVwNeBh4BV7UmpUxjcLN9RVQXcD1ze1t8E3DO0rU1t/nLgvjZekjQGS2cfwnuAXwEeS/JIq/0mg6ef1jC4XPQs8GsAVfVEkruAbzJ48urqqnoVIMk1wL3AEmBbVT3Rtvcx4M4kvwX8GYOQor1+PskkgzOMjfP4rJKkeZo1NKrqTxh9b2HnDOtcD1w/or5z1HpV9TQ/urw1XP9r4IrZepQkLQ5/ES5J6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6zhkaSc5Pcn+TJJE8k+fVWPz3JriR72uuyVk+Sm5JMJnk0yflD29rUxu9Jsmmo/s4kj7V1bkqSmfYhSRqPnjONV4DfqKpfANYBVydZDWwFdlfVKmB3ew9wCbCqTVuAm2EQAMC1wLuAC4Brh0Lg5jZ2ar31rX60fUiSxmDW0Kiq/VX1p23+JeBJ4BxgA7C9DdsOXNbmNwC318ADwGlJzgYuBnZV1aGqOgzsAta3ZW+qqq9VVQG3T9vWqH1IksbgmO5pJFkJvAN4EDirqvbDIFiAM9uwc4Dnhlbb22oz1feOqDPDPiRJY9AdGkneCPwB8NGq+suZho6o1Rzq3ZJsSTKRZOLgwYPHsqok6Rh0hUaSn2AQGL9fVX/Yys+3S0u01wOtvhc4d2j1FcC+WeorRtRn2scRquqWqlpbVWuXL1/e85EkSXPQ8/RUgFuBJ6vqd4cW7QCmnoDaBNwzVL+qPUW1DnixXVq6F7goybJ2A/wi4N627KUk69q+rpq2rVH7kCSNwdKOMe8BfgV4LMkjrfabwA3AXUk2A98BrmjLdgKXApPA94EPAVTVoSSfAh5q466rqkNt/iPAbcAbgC+3iRn2IUkag1lDo6r+hNH3HQAuHDG+gKuPsq1twLYR9Qng7SPqL4zahyRpPPxFuCSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRus4ZGkm1JDiR5fKj2ySR/keSRNl06tOzjSSaTPJXk4qH6+labTLJ1qH5ekgeT7EnyhSSntPqp7f1kW75yoT60JGlues40bgPWj6jfWFVr2rQTIMlqYCPwtrbO7yVZkmQJ8BngEmA1cGUbC/Dptq1VwGFgc6tvBg5X1c8DN7ZxkqQxmjU0quorwKHO7W0A7qyql6vqGWASuKBNk1X1dFX9ALgT2JAkwPuBu9v624HLhra1vc3fDVzYxkuSxmQ+9zSuSfJou3y1rNXOAZ4bGrO31Y5Wfwvwvap6ZVr9iG215S+28ZKkMZlraNwM/BywBtgP/E6rjzoTqDnUZ9rWayTZkmQiycTBgwdn6luSNA9zCo2qer6qXq2qHwKfZXD5CQZnCucODV0B7Juh/l3gtCRLp9WP2FZb/maOcpmsqm6pqrVVtXb58uVz+UiSpA5zCo0kZw+9/SAw9WTVDmBje/LpPGAV8HXgIWBVe1LqFAY3y3dUVQH3A5e39TcB9wxta1Obvxy4r42XJI3J0tkGJLkDeC9wRpK9wLXAe5OsYXC56Fng1wCq6okkdwHfBF4Brq6qV9t2rgHuBZYA26rqibaLjwF3Jvkt4M+AW1v9VuDzSSYZnGFsnPenlSTNy6yhUVVXjijfOqI2Nf564PoR9Z3AzhH1p/nR5a3h+l8DV8zWnyRp8fiLcElSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdZs1NJJsS3IgyeNDtdOT7Eqyp70ua/UkuSnJZJJHk5w/tM6mNn5Pkk1D9Xcmeaytc1OSzLQPSdL49Jxp3Aasn1bbCuyuqlXA7vYe4BJgVZu2ADfDIACAa4F3ARcA1w6FwM1t7NR662fZhyRpTGYNjar6CnBoWnkDsL3NbwcuG6rfXgMPAKclORu4GNhVVYeq6jCwC1jflr2pqr5WVQXcPm1bo/YhSRqTud7TOKuq9gO01zNb/RzguaFxe1ttpvreEfWZ9iFJGpOFvhGeEbWaQ/3YdppsSTKRZOLgwYPHurokqdNcQ+P5dmmJ9nqg1fcC5w6NWwHsm6W+YkR9pn28RlXdUlVrq2rt8uXL5/iRJEmzmWto7ACmnoDaBNwzVL+qPUW1DnixXVq6F7goybJ2A/wi4N627KUk69pTU1dN29aofUiSxmTpbAOS3AG8FzgjyV4GT0HdANyVZDPwHeCKNnwncCkwCXwf+BBAVR1K8ingoTbuuqqaurn+EQZPaL0B+HKbmGEfkqQxmTU0qurKoyy6cMTYAq4+yna2AdtG1CeAt4+ovzBqH5Kk8fEX4ZKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6zSs0kjyb5LEkjySZaLXTk+xKsqe9Lmv1JLkpyWSSR5OcP7SdTW38niSbhurvbNufbOtmPv1KkuZnIc403ldVa6pqbXu/FdhdVauA3e09wCXAqjZtAW6GQcgA1wLvAi4Arp0KmjZmy9B66xegX0nSHB2Py1MbgO1tfjtw2VD99hp4ADgtydnAxcCuqjpUVYeBXcD6tuxNVfW1qirg9qFtSZLGYL6hUcAfJXk4yZZWO6uq9gO01zNb/RzguaF197baTPW9I+qvkWRLkokkEwcPHpznR5IkHc3Sea7/nqral+RMYFeSP59h7Kj7ETWH+muLVbcAtwCsXbt25BhJ0vzN60yjqva11wPAFxnck3i+XVqivR5ow/cC5w6tvgLYN0t9xYi6JGlM5hwaSX4qyU9PzQMXAY8DO4CpJ6A2Afe0+R3AVe0pqnXAi+3y1b3ARUmWtRvgFwH3tmUvJVnXnpq6amhbkqQxmM/lqbOAL7anYJcC/6Oq/neSh4C7kmwGvgNc0cbvBC4FJoHvAx8CqKpDST4FPNTGXVdVh9r8R4DbgDcAX26TJGlM5hwaVfU08Isj6i8AF46oF3D1Uba1Ddg2oj4BvH2uPUqSFpa/CJckdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUrcTPjSSrE/yVJLJJFvH3Y8kvZ6d0KGRZAnwGeASYDVwZZLV4+1Kkl6/TujQAC4AJqvq6ar6AXAnsGHMPUnS69bScTcwi3OA54be7wXeNaZepLFbufVL425BJ7Bnb/jAcd/HiR4aGVGr1wxKtgBb2tu/SvLUce1q/s4AvjvuJjrYZ5NPL8hmTpbjCSdPr/Y5ZJ7f05/tGXSih8Ze4Nyh9yuAfdMHVdUtwC2L1dR8JZmoqrXj7mM29rmwTpY+4eTp1T4X34l+T+MhYFWS85KcAmwEdoy5J0l63TqhzzSq6pUk1wD3AkuAbVX1xJjbkqTXrRM6NACqaiewc9x9LLCT5VKafS6sk6VPOHl6tc9FlqrX3FeWJGmkE/2ehiTpBGJoHAdJTk+yK8me9rpsxJg1Sb6W5Ikkjyb5l0PLbkvyTJJH2rRmgfub8U+zJDk1yRfa8geTrBxa9vFWfyrJxQvZ1xx7/fdJvtmO4e4kPzu07NWhY3hcH6Do6PNXkxwc6uffDC3b1L4re5JsGnOfNw71+K0k3xtatpjHc1uSA0keP8ryJLmpfY5Hk5w/tGwxj+dsff6r1t+jSb6a5BeHlj2b5LF2PCeOZ58LqqqcFngCfhvY2ua3Ap8eMeYfAKva/N8H9gOntfe3AZcfp96WAN8G3gqcAnwDWD1tzL8F/mub3wh8oc2vbuNPBc5r21lyHI9jT6/vA/5um//IVK/t/V8t0n/ePX3+KvBfRqx7OvB0e13W5peNq89p4/8dg4dPFvV4tn39U+B84PGjLL8U+DKD33KtAx5c7OPZ2ee7p/bP4M8hPTi07FngjMU6pgs1eaZxfGwAtrf57cBl0wdU1beqak+b3wccAJYvQm89f5pluP+7gQuTpNXvrKqXq+oZYLJtb2y9VtX9VfX99vYBBr/lWWzz+XM3FwO7qupQVR0GdgHrT5A+rwTuOE69zKiqvgIcmmHIBuD2GngAOC3J2Szu8Zy1z6r6ausDxvf9XFCGxvFxVlXtB2ivZ840OMkFDP7l9+2h8vXtlPbGJKcuYG+j/jTLOUcbU1WvAC8Cb+lcdyEd6/42M/jX55SfTDKR5IEkrwnuBdTb579o/5nenWTqR6uLeUy799Uu850H3DdUXqzj2eNon2Wxv6PHYvr3s4A/SvJw+6sWJ4UT/pHbE1WSPwb+3ohFnzjG7ZwNfB7YVFU/bOWPA/+PQZDcAnwMuG7u3R65yxG16Y/QHW1M1591WUDd+0vyy8Ba4J8NlX+mqvYleStwX5LHqurbo9ZfhD7/F3BHVb2c5MMMzuTe37nuQjmWfW0E7q6qV4dqi3U8e5wo39EuSd7HIDT+yVD5Pe14ngnsSvLn7czlhOaZxhxV1S9V1dtHTPcAz7cwmAqFA6O2keRNwJeA/9BOsae2vb+ddr8M/DcW9hJQz59m+dsxSZYCb2ZwCt71Z10WUNf+kvwSg7D+5+2YAX972Y+qehr4P8A7xtVnVb0w1NtngXf2rruYfQ7ZyLRLU4t4PHsc7bMs9nd0Vkn+MfA5YENVvTBVHzqeB4Avcnwv9S6ccd9U+XGcgP/EkTfCf3vEmFOA3cBHRyw7u70G+M/ADQvY21IGNwfP40c3Q982bczVHHkj/K42/zaOvBH+NMf3RnhPr+9gcFlv1bT6MuDUNn8GsIcZbvouQp9nD81/EHigzZ8OPNP6XdbmTx9Xn23cP2RwkzbjOJ5D+1zJ0W8wf4Ajb4R/fbGPZ2efP8Pg3t+7p9V/CvjpofmvAuuPZ58L9nnH3cCP48Tg+v/u9l+s3VNfWgaXTz7X5n8Z+BvgkaFpTVt2H/AY8Djw34E3LnB/lwLfav9j+4lWu47Bv9QBfhL4n+3L/nXgrUPrfqKt9xRwySIcy9l6/WPg+aFjuKPV392O4Tfa6+Yx9/kfgSdaP/cD/2ho3X/djvUk8KFx9tnef5Jp/1AZw/G8g8EThX/D4OxhM/Bh4MNteRj8H7R9u/WzdkzHc7Y+PwccHvp+TrT6W9ux/Eb7XnziePa5kJO/CJckdfOehiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkbv8faD/l6Mw/BBkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizing the data points according to number fraudulent and non-fraudulent transactions\n",
    "a=dataframe.groupby('Class').V1.count()\n",
    "print(a)\n",
    "plt.bar(range(0,2),a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the visualized plot, it is evident that the number of fraudulent transactions is approximately 0.2% of the total number of transactions. This clearly indicates that our dataset is highly imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199364, 30) (199364, 1)\n",
      "(85443, 30) (85443, 1)\n"
     ]
    }
   ],
   "source": [
    "#Splitting the data into 70% train and 30% test data and creating inputs for our classification model\n",
    "X = dataframe.loc[:,dataframe.columns != 'Class']\n",
    "Y = dataframe.loc[:,dataframe.columns == 'Class']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.3, random_state = 0)\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#Applying Logistic Regression to imbalanced data \n",
    "log=LogisticRegression()\n",
    "log.fit(X_train,Y_train)\n",
    "Y_pred = log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[85285,    11],\n",
       "       [   70,    77]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9990519995786665"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5238095238095238"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recall obtained on applying our model to the imbalaced data is very low. To obtain a high recall score, we need to use techniques such as undersampling or SMOTE so that we can have comparable number of fraudulent and non-fraudulent transactions, which will fetch us better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_fraud_indices=dataframe[dataframe.Class==0].index\n",
    "fraud_indices=dataframe[dataframe.Class==1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random undersampling of non-fraudulent transactions\n",
    "random_indices_nf=np.random.choice(non_fraud_indices,492,replace=False)\n",
    "under_sample_indices=np.concatenate([fraud_indices,random_indices_nf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "0    492\n",
      "1    492\n",
      "Name: V1, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "under_sample=dataframe.loc[under_sample_indices]\n",
    "a=under_sample.groupby('Class').V1.count()\n",
    "print(a)\n",
    "plt.bar(range(0,2),a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(688, 30) (688, 1)\n",
      "(296, 30) (296, 1)\n"
     ]
    }
   ],
   "source": [
    "#Applying Logistic Regression to undersampled data\n",
    "X_under = under_sample.loc[:,under_sample.columns != 'Class']\n",
    "Y_under = under_sample.loc[:,under_sample.columns == 'Class']\n",
    "X_under_train, X_under_test, Y_under_train, Y_under_test = train_test_split(X_under,Y_under,test_size = 0.3, random_state = 0)\n",
    "print(X_under_train.shape, Y_under_train.shape)\n",
    "print(X_under_test.shape, Y_under_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "lr_under = LogisticRegression()\n",
    "lr_under.fit(X_under_train,Y_under_train)\n",
    "Y_under_pred = lr_under.predict(X_under_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[139,  10],\n",
       "       [ 10, 137]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_under_test,Y_under_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9324324324324325"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_under_test,Y_under_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9319727891156463"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(Y_under_test,Y_under_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recall score obtained after undersampling of data has improved significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in d:\\anaconda\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in d:\\anaconda\\lib\\site-packages (from imblearn) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.8.2 in d:\\anaconda\\lib\\site-packages (from imbalanced-learn->imblearn) (1.15.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in d:\\anaconda\\lib\\site-packages (from imbalanced-learn->imblearn) (0.20.1)\n",
      "Requirement already satisfied: scipy>=0.13.3 in d:\\anaconda\\lib\\site-packages (from imbalanced-learn->imblearn) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#Using SMOTE for oversampling of fraudulent data\n",
    "smt=SMOTE()\n",
    "X_smote, Y_smote = smt.fit_sample(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([284315, 284315], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(Y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398041, 30) (398041,)\n",
      "(170589, 30) (170589,)\n"
     ]
    }
   ],
   "source": [
    "#Applying Logistic Regression to synthetic data created using SMOTE\n",
    "X_smote_train, X_smote_test, Y_smote_train, Y_smote_test = train_test_split(X_smote,Y_smote,test_size = 0.3, random_state = 0)\n",
    "print(X_smote_train.shape, Y_smote_train.shape)\n",
    "print(X_smote_test.shape, Y_smote_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lr_smote = LogisticRegression()\n",
    "lr_smote.fit(X_smote_train,Y_smote_train)\n",
    "Y_smote_pred = lr_smote.predict(X_smote_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[83682,  1490],\n",
       "       [ 4109, 81308]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_smote_test,Y_smote_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9671784229932763"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_smote_test,Y_smote_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9518948218738659"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(Y_smote_test,Y_smote_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recall score obtained after the application of SMOTE is even greater than that obtained after undersampling. This suggests that undersampling and SMOTE can be used in combination to obtain even higher recall scores while dealing with imbalanced datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
